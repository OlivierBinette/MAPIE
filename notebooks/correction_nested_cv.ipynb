{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc90d412",
   "metadata": {},
   "source": [
    "# Nested-CV "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e485027",
   "metadata": {},
   "source": [
    "Cet exemple compare les stratégies de validation croisée non imbriquée et imbriquée pour l'estimation des intervalles de prédiction avec `MapieRegressor`.\n",
    "\n",
    "Dans la méthode séquentielle standard, une recherche de paramètres par validation croisée est effectuée sur l'ensemble du jeu d'entraînement. \n",
    "Le \"meilleur modèle\", le modèle avec le jeu de paramètres donnant le meilleur score, est ensuite utilisé dans MAPIE pour estimer les intervalles de confiance associés aux prédictions. \n",
    "Une limitation de cette méthode est que les résidus utilisés par MAPIE sont calculés sur l'ensemble du jeu de validation, qui avait été utilisé dans l'étape précédente pour optimiser le modèle via le réglage des hyperparamètres.\n",
    "Cette méthode séquentielle conduit donc MAPIE à être légèrement trop optimiste avec les intervalles de confiance.\n",
    "\n",
    "Pour résoudre ce problème, une autre option consiste à effectuer une recherche de paramètres par validation croisée imbriquée directement dans l'estimateur `MapieRegressor` afin de trouver le *meilleur* modèle perturbé pour son jeu de données *out-of-fold* d'entraînement correspondant. \n",
    "Cela garantit que les données du dernier pli servant à calculer les résidus estimés par MAPIE ne sont jamais vus par l'algorithme au préalable pour entraîner le modèle perturbé. Cependant, cette méthode est beaucoup plus lourde et augmente sensiblement le temps de calcul puisqu'elle entraîne $N \\times P$ calculs, où $N$ est le nombre de modèles out-of-fold et $P$ le nombre de validations croisées de recherche de paramètres, contre $N + P$ pour l'approche non imbriquée.\n",
    "\n",
    "Ici, nous comparons les deux stratégies sur le jeu de données *Boston dataset*. Nous utilisons le régresseur Random Forest comme régresseur de base pour la stratégie CV+. Pour alléger les calculs, nous adoptons une stratégie de recherche de paramètres `RandomizedSearchCV` avec un faible nombre d'itérations et un état aléatoire reproductible.\n",
    "\n",
    "Les deux approches donnent des prédictions légèrement différentes, l'approche CV imbriquée estimant des largeurs d'intervalle de prédiction légèrement plus grandes de quelques pourcents au maximum (à part quelques exceptions).\n",
    "\n",
    "Pour cet exemple, les deux approches donnent des scores similaires et des couvertures effectives identiques.\n",
    "\n",
    "Dans le cas général, l'approche recommandée est d'utiliser la validation croisée emboîtée, car elle ne sous-estime pas les résidus et donc les intervalles de prédiction. Cependant, dans cet exemple particulier, les couvertures effectives des méthodes emboîtées et non emboîtées sont identiques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21944273",
   "metadata": {},
   "source": [
    "## 1. Importation des données et définition du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fedcc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "from scipy.stats import randint\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117b0111",
   "metadata": {},
   "source": [
    "**Exercice.** Commençons par importer `MapieRegressor et `coverage_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88894b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapie.estimators import MapieRegressor  # correction\n",
    "from mapie.metrics import coverage_score  # correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84370112",
   "metadata": {},
   "source": [
    "Choisissons ensuite les paramètres définissant la validation-croisée et l'estimation des intervalles de confiance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a6f121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation and prediction-interval parameters.\n",
    "test_size = 0.2\n",
    "cv = 5\n",
    "n_iter = 5\n",
    "alpha = 0.05\n",
    "method = \"plus\"\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e795be9",
   "metadata": {},
   "source": [
    "**Exercice.** Importons le jeu de données Boston et séparons le en deux jeux de données d'entraînement et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7599b344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Boston data\n",
    "X_boston, y_boston = load_boston(return_X_y=True)\n",
    "\n",
    "# Split the data into training and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_boston, y_boston, test_size=test_size, random_state=random_state  # correction\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf8979b",
   "metadata": {},
   "source": [
    "**Exercice.** Définissons notre modèle `RandomForestRegressor` comme modèle de base et le domaine des paramètres exploré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121b5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Random Forest model as base regressor with parameter ranges.\n",
    "rf_model = RandomForestRegressor(random_state=random_state, verbose=0)\n",
    "rf_params = {\n",
    "    \"max_depth\": randint(2, 30),\n",
    "    \"n_estimators\": randint(10, 1e3)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afe36eb",
   "metadata": {},
   "source": [
    "## 2. Validation-croisée non-imbriquée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02340d8",
   "metadata": {},
   "source": [
    "**Exercice.** Effectuons l'étude de paramètres par validation croisée. Pour ce faire, [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/grid_search.html#randomized-parameter-search) est uilisé. Il suffit de définir l'estimateur, la distribution des paramètres, le nombre d'itérations, et le nombre de splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ee9990",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_obj = RandomizedSearchCV(\n",
    "    rf_model,  # correction\n",
    "    param_distributions=rf_params,  # correction\n",
    "    n_iter=n_iter,  # correction\n",
    "    cv=cv,  # correction\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    verbose=0,\n",
    "    random_state=random_state,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "cv_obj.fit(X_train, y_train)\n",
    "best_est = cv_obj.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27124e83",
   "metadata": {},
   "source": [
    "**Question.** Quel est le jeu de paramètres donnant le meilleur score ? Comment varie t-il avec la graine aléatoire ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1fab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_obj.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be049fca",
   "metadata": {},
   "source": [
    "**Exercice.** Implémentons maintenant l'estimateur de base déterminé par l'étude de paramètres dans `MapieRegressor` pour estimer les intervalles de prédiction associés. Il suffit ici de déterminer l'estimateur, la méthode (\"plus\"), et le nombre de plis pour la validation croisée. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdfdf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapie_non_nested = MapieRegressor(\n",
    "    best_est,  # correction\n",
    "    method=\"plus\",  # correction\n",
    "    cv=cv,  # correction\n",
    "    ensemble=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "mapie_non_nested.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674bf8ca",
   "metadata": {},
   "source": [
    "**Exercice.** Calculons les intervalles de prédiction sur `X_test` en définissant le paramètre `alpha`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37a41fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_non_nested = mapie_non_nested.predict(\n",
    "    X_test, alpha=alpha  # correction\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb26216",
   "metadata": {},
   "source": [
    "**Question.** Quel est l'objet retourné par `MapieRegressor` et quelle est sa taille ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c964a527",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(y_preds_non_nested), len(y_preds_non_nested))  # correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f62974",
   "metadata": {},
   "source": [
    "**Exercice.** Calculons la RMSE sur le jeu de test, puis la largeur moyenne des intervalles de prédiction, et le taux de couverture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327b6c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_non_nested = mean_squared_error(\n",
    "    y_test, y_preds_non_nested[0], squared=False  # correction\n",
    ")\n",
    "widths_non_nested = (\n",
    "    y_preds_non_nested[1][:, 1, 0] - y_preds_non_nested[1][:, 0, 0]  # correction\n",
    ")\n",
    "coverage_non_nested = coverage_score(\n",
    "    y_test, y_preds_non_nested[1][:, 0, 0], y_preds_non_nested[1][:, 1, 0]  # correction\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906901c3",
   "metadata": {},
   "source": [
    "## 3. Validation croisée imbriquée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60683133",
   "metadata": {},
   "source": [
    "**Exercice.** Implémentons cette fois-ci directement l'objet `RandomizedSearchCV` dans `MapieRegressor` afin d'effectuer l'étude de paramètres par validation croisée pour chaque modèle \"perturbé\" servant à calculer les résidus dans MAPIE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b998056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested approach with the CV+ strategy using the Random Forest model.\n",
    "cv_obj = RandomizedSearchCV(\n",
    "    rf_model,  # correction\n",
    "    param_distributions=rf_params,  # correction\n",
    "    n_iter=n_iter,  # correction\n",
    "    cv=cv,  # correction\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    verbose=0,\n",
    "    random_state=random_state,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "mapie_nested = MapieRegressor(\n",
    "    cv_obj,  # correction\n",
    "    method=\"plus\",  # correction\n",
    "    cv=cv,  # correction\n",
    "    ensemble=True\n",
    ")\n",
    "mapie_nested.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee57bc9a",
   "metadata": {},
   "source": [
    "**Exercice.** Calculons les intervalles de prédiction sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883904e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_nested = mapie_nested.predict(\n",
    "    X_test, alpha=alpha  # correction\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e2012b",
   "metadata": {},
   "source": [
    "**Exercice.** Calculons la RMSE sur le jeu de test, puis la largeur moyenne des intervalles de prédiction, et le taux de couverture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1694530",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_nested = mean_squared_error(\n",
    "    y_test, y_preds_nested[0], squared=False  # correction\n",
    ")\n",
    "coverage_nested = coverage_score(\n",
    "    y_test, y_preds_nested[1][:, 0, 0], y_preds_nested[1][:, 1, 0]  # correction\n",
    ")\n",
    "widths_nested = (\n",
    "    y_preds_nested[1][:, 1, 0] - y_preds_nested[1][:, 0, 0]  # correction\n",
    ")\n",
    "width_diff = (widths_non_nested - widths_nested)/widths_non_nested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7536cbc5",
   "metadata": {},
   "source": [
    "## 4. Visualisation des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec63354c",
   "metadata": {},
   "source": [
    "Comparons les scores et les taux de couverture obtenus avec les deux approches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2133918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print scores and effective coverages.\n",
    "print(\n",
    "    \"Scores and effective coverages for the CV+ strategy using the \"\n",
    "    \"Random Forest model.\"\n",
    ")\n",
    "print(\n",
    "    \"Score on the test set for the non-nested and nested CV approaches: \",\n",
    "    f\"{score_non_nested: .3f}, {score_nested: .3f}\"\n",
    ")\n",
    "print(\n",
    "    \"Effective coverage on the test set for the non-nested \"\n",
    "    \"and nested CV approaches: \",\n",
    "    f\"{coverage_non_nested: .3f}, {coverage_nested: .3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae5458d",
   "metadata": {},
   "source": [
    "Comparons les largeurs des intervalles de prédiction obtenus avec les deux méthodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062386f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "min_width = np.min([widths_nested, widths_non_nested])\n",
    "max_width = np.max([widths_nested, widths_non_nested])\n",
    "# data\n",
    "fig.add_trace(go.Scatter(\n",
    "    name=\"data\",\n",
    "    x=widths_nested,\n",
    "    y=widths_non_nested,\n",
    "    mode=\"markers\",\n",
    "    marker=dict(color=\"#1f77b4\")\n",
    "))\n",
    "# linear curve\n",
    "fig.add_trace(go.Scatter(\n",
    "    name=\"predictions\",\n",
    "    x=[0, 100],\n",
    "    y=[0, 100],\n",
    "    mode=\"lines\",\n",
    "    line=dict(color=\"#ff7f0e\", dash='solid')\n",
    "))\n",
    "fig.update_xaxes(range=[14.5, 16.])\n",
    "fig.update_yaxes(range=[14.5, 16.])\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=600,\n",
    "    height=600,\n",
    "    xaxis_title=\"Prediction interval width using the nested CV approach\",\n",
    "    yaxis_title=\"Prediction interval width using the non-nested CV approach\",\n",
    "    hovermode=\"x\",\n",
    "    showlegend=False\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6831de",
   "metadata": {},
   "source": [
    "Visualisons la distribution des différences de largeur entre les deux méthodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff824dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=width_diff,\n",
    "    nbinsx=20,\n",
    "    marker_color=\"#1f77b4\"\n",
    "    )\n",
    ")\n",
    "# linear curve\n",
    "fig.add_trace(go.Scatter(\n",
    "    name=\"predictions\",\n",
    "    x=[0, 0],\n",
    "    y=[0, np.histogram(width_diff, bins=20)[0].max()],\n",
    "    mode=\"lines\",\n",
    "    line=dict(color=\"#ff7f0e\", dash='solid')\n",
    "))\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=600,\n",
    "    height=500,\n",
    "    xaxis_title=\"[width(non-nested CV) - width(nested CV)] / width(non-nested CV)\",\n",
    "    yaxis_title=\"Counts\",\n",
    "    hovermode=\"x\",\n",
    "    showlegend=False\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91afccdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbl-mapie",
   "language": "python",
   "name": "bbl-mapie"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

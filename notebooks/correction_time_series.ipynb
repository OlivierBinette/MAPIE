{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63aeca25",
   "metadata": {},
   "source": [
    "# Estimation d'intervalles de prédiction pour la prévision de séries temporelles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191f19d7",
   "metadata": {},
   "source": [
    "Dans cet exemple, nous utilisons MAPIE pour estimer les intervalles de prédiction associés aux prévision de séries temporelles. Nous utilisons ici l'approche standard de validation croisée pour estimer les résidus et les intervalles de prédiction associés.\n",
    "\n",
    "Nous utilisons ici le dataset de consommation d'électricité de Victoria utilisé dans le livre \"Forecasting : Principles and Practice\" par R. J. Hyndman et G. Athanasopoulos.\n",
    "La demande d'électricité présente des variations saisonnières quotidiennes et hebdomadaires et est influencée par la températur, considérée ici comme une variable exogène.\n",
    "\n",
    "Les données sont modélisées par un modèle de type Random Forest optimisé par un `RandomizedSearchCV` en utilisant une validation croisée séquentielle `TimeSeriesSplit`. Le meilleur modèle est ensuite introduit dans `MapieRegressor` pour estimer les intervalles de prédiction associés. Nous considérons deux stratégies, avec les méthodes de rééchantillonnage CV et CV+ et en utilisant une méthode standard `KFold` pour estimer les résidus. La garantie mathématique de la validation croisée séquentielle `TimeSeriesSplit` dans MAPIE pour l'estimation des intervalles de prédiction n'est pas encore validée et sera donc implémentée ultérieurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2814f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import randint\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from mapie.estimators import MapieRegressor\n",
    "from mapie.metrics import coverage_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b1ff7a",
   "metadata": {},
   "source": [
    "Commençons par charger les données et extraire les variables temporelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4748aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df = pd.read_csv(\n",
    "    \"../data/demand_temperature.csv\",\n",
    "    parse_dates=True,\n",
    "    index_col=0\n",
    ")\n",
    "demand_df[\"Date\"] = pd.to_datetime(demand_df.index)\n",
    "demand_df[\"Weekofyear\"] = demand_df.Date.dt.isocalendar().week.astype('int64')\n",
    "demand_df[\"Weekday\"] = demand_df.Date.dt.isocalendar().day.astype('int64')\n",
    "demand_df[\"Hour\"] = demand_df.index.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66325583",
   "metadata": {},
   "source": [
    "Séparons le jeu de données en jeux d'entraînement et de test, le jeu de test étant sur les deux dernières semaines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd02a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_forecast_steps = 24 * 7 * 2\n",
    "demand_train = demand_df.iloc[:-num_forecast_steps, :].copy()\n",
    "demand_test = demand_df.iloc[-num_forecast_steps:, :].copy()\n",
    "X_train = demand_train.loc[:, [\"Weekofyear\", \"Weekday\", \"Hour\", \"Temperature\"]]\n",
    "y_train = demand_train[\"Demand\"]\n",
    "X_test = demand_test.loc[:, [\"Weekofyear\", \"Weekday\", \"Hour\", \"Temperature\"]]\n",
    "y_test = demand_test[\"Demand\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec95991",
   "metadata": {},
   "source": [
    "Définissons les paramètres d'entrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5acb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 10\n",
    "n_splits = 5\n",
    "random_state = 59\n",
    "rf_model = RandomForestRegressor(random_state=random_state)\n",
    "rf_params = {\n",
    "    \"max_depth\": randint(2, 30),\n",
    "    \"n_estimators\": randint(10, 1e3)\n",
    "}\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f8ec6c",
   "metadata": {},
   "source": [
    "**Exercice.** Optimisons le modèle Random Forest par une étude de paramètres `RandomizedSearchCV` mais cette fois ci en considérant une validation croisée séquentielle [`TimeSeriesSplit`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html) afin que chaque jeu d'entraînement soit toujours antérieure au jeu de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca89aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "cv_obj = RandomizedSearchCV(\n",
    "    rf_model,  # correction\n",
    "    param_distributions=rf_params,  # correction\n",
    "    n_iter=n_iter,\n",
    "    cv=tscv,  # correction\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    random_state=random_state,\n",
    "    verbose=0,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "cv_obj.fit(X_train, y_train)\n",
    "best_est = cv_obj.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18b1d41",
   "metadata": {},
   "source": [
    "**Exercice.** Estimons ensuite les intervalles de prédiction associées au meilleur modèle Random Forest avec les stratégies CV et CV+. Calculons ensuite les couvertures effectives et les largeurs moyennes des intervalles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53160263",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = {\n",
    "    \"cv\": dict(method=\"base\", cv=n_splits),\n",
    "    \"cv_plus\": dict(method=\"plus\", cv=n_splits),\n",
    "}\n",
    "y_pred, y_pis, coverages, widths = {}, {}, {}, {}\n",
    "for strategy, params in strategies.items():\n",
    "    mapie = MapieRegressor(best_est, **params)\n",
    "    mapie.fit(X_train, y_train)\n",
    "    y_pred_, y_pis_ = mapie.predict(X_test, alpha=alpha)  # correction\n",
    "    y_pred[strategy] = y_pred_\n",
    "    y_pis[strategy] = y_pis_\n",
    "    coverages[strategy] = coverage_score(\n",
    "        y_test, y_pis_[:, 0, 0], y_pis_[:, 1, 0]  # correction\n",
    "    )\n",
    "    widths[strategy] = (\n",
    "        y_pis_[:, 1, 0] - y_pis_[:, 0, 0]  # correction\n",
    "    ).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608cb867",
   "metadata": {},
   "source": [
    "Comparons maintenant les résultats avec les deux stratégies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1438ddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for strategy in strategies:\n",
    "    print(\n",
    "        \"Coverage and prediction interval width mean for the \"\n",
    "        f\"{strategy:8} strategy: \"\n",
    "        f\"{coverages[strategy]:.3f}, {widths[strategy]:.3f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eae9ff",
   "metadata": {},
   "source": [
    "Visualisons enfin les intervalles de prédiction sur nos données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e394f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "# lower/upper bounds\n",
    "fig.add_trace(go.Scatter(\n",
    "    name=\"lower bound\",\n",
    "    x=demand_test.index,\n",
    "    y=y_pis[\"cv_plus\"][:, 0, 0],\n",
    "    mode=\"lines\",\n",
    "    line=dict(color=\"#1f77b4\", dash='solid', width=0.1)\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    name=\"upper bound\",\n",
    "    x=demand_test.index,\n",
    "    y=y_pis[\"cv_plus\"][:, 1, 0],\n",
    "    mode=\"lines\",\n",
    "    fill=\"tonexty\",\n",
    "    line=dict(color=\"#1f77b4\", dash='solid', width=0.1)\n",
    "))\n",
    "# predictions\n",
    "fig.add_trace(go.Scatter(\n",
    "    name=\"predictions\",\n",
    "    x=demand_test.index,\n",
    "    y=y_pred[\"cv_plus\"],\n",
    "    mode=\"lines\",\n",
    "    line=dict(color=\"#1f77b4\", dash='solid')\n",
    "))\n",
    "# data\n",
    "fig.add_trace(go.Scatter(\n",
    "    name=\"lower bound\",\n",
    "    x=demand_test.index,\n",
    "    y=demand_test.Demand,\n",
    "    mode=\"lines\",\n",
    "    line=dict(color=\"#ff7f0e\", dash='solid')\n",
    "))\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=400,\n",
    "    yaxis_title=\"Hourly demand (GW)\",\n",
    "    hovermode=\"x\",\n",
    "    showlegend=False\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbl-mapie",
   "language": "python",
   "name": "bbl-mapie"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
